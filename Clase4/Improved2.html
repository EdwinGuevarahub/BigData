<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Challenge: Investigate the 90% Accuracy Limit</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis"></script>
</head>

<body>
  <h1>Challenge: Investigate the 90% Accuracy Limit</h1>
  <p>In this challenge, you will explore why the LeNet model in our example consistently achieves around <strong>90%
      accuracy</strong> on the MNIST dataset. Your goal is to hypothesize, experiment, and explain the reasons behind
    this plateau in accuracy, and possibly suggest improvements.</p>
  <h2>Deliverables</h2>
  <ol>
    <li><strong>Report Your Findings:</strong>
      <ul>
        <li>Summarize your observations about why the model is limited to 90% accuracy.</li>
        <li>Include screenshots or plots (e.g., loss curves, accuracy comparisons, or visualized data) to support your
          conclusions.</li>
      </ul>
    </li>
    <li><strong>Experiment Results:</strong>
      <ul>
        <li>Share the changes you made (if any) to improve accuracy.</li>
        <li>Provide before-and-after accuracy metrics and explain why your adjustments worked (or didn’t work).</li>
      </ul>
    </li>
    <li><strong>Propose Solutions:</strong>
      <ul>
        <li>Improvement of the current implementation that could help achieve higher accuracy.</li>
      </ul>
    </li>
  </ol>
  <button onclick="trainModel()">Train Model</button>
  <p id="status">Status: Ready to train</p>
  <p id="accuracy"></p>

  <h2>Hipótesis probadas</h2>
  <ol>
    <li><b>Numero de clases diferente de 10:</b> Se validaron mediante una funcion "countClassesFromOneHot", la cual imprimer un array con la cantidad de clases
      y la distribucion de la misma, obteniendo 10 clases con las siguientes cantidades
        <ol>
          <li>0: 6424</li>
          <li>1: 7314</li>
          <li>2: 6502</li>
          <li>3: 6648</li>
          <li>4: 6289</li>
          <li>5: 5879</li>
          <li>6: 6375</li>
          <li>7: 6743</li>
          <li>8: 6363</li>
          <li>9: 6463</li>
        </ol>
    </li>
    <li><b>Red Neuronal demasiado compleja por ende sobre entrenamiento:</b> Debido a que alcanza el 90% de accuracy en la primero a lo sumo 2da iteracion,
      se ajusto la red neuronal experimentando con lo siguiente:
        <ol>
          <li><b>Anadir capas de drop.</b> No se evidencio nada concluyente y ademas tardaba mas el proceso de entrenamiento</li>
          <li><b>Disminuir la complejidad de la red disminuyendo la cantidad de filtros.</b> Esto aceleraba la "convergencia", garantizando que en la primera iteracion se llegaba al 90% con delta bastante pequeno</li>
          <li><b>Disminuir la complejidad de la red quitando 1 capa convolucional y 1 capa de pooling.</b> Esto hizo la diferencia entre el error de entrenamiento y de test fuese menor desde la primera iteracion en comparacion al resto de pruebas</li>
          <li><b>Reemplazar avgpooling por maxpooling.</b>No se evidencio ninguna repercusión.</li>
          <li><b>Modificar la proporcion entre datos de entrenamiento y datos de prueba.</b>No se evidencio ninguna repercusión.</li>
        </ol>
        Se anadio codigo para graficar los valores de error y accuracy en funcion de la cantidad de epocas, de ahi pudimos evidenciar que la primera ejecucion bastaba para
        obtener un accurancy del 90%. 
    </li>
    <li><b>Clase faltante en subset de pruebas:</b> Se imprimieron las clases para el dataset tanto de entrenamiento como de prueba, no se evidencia que este desbalanceado</li>
  </ol>
  <h3>Conclusiones</h3>
  <ol>
    <li>Ninguna de las hipotesis descritas en la sección anterior pudo ayudar en la mejora o siquiera modificacion del valor de accuracy</li>
    <li>El accuracy no pudo ni ser modificado, siempre termino convergiendo hacia 90%</li>
  </ol>

  <script>
    function countClassesFromOneHot(labelsArray,NUM_CLASSES) {
      // Número de clases en el one-hot encoding
      const numClasses = NUM_CLASSES;

      // Validar que el tamaño sea divisible por el número de clases
      if (labelsArray.length % numClasses !== 0) {
        console.error("El array no parece estar correctamente codificado en one-hot.");
        return;
      }

      // Inicializar un contador para cada clase
      const labelCounts = Array(numClasses).fill(0);

      // Iterar por el array en bloques del tamaño de las clases
      for (let i = 0; i < labelsArray.length; i += numClasses) {
        for (let classIndex = 0; classIndex < numClasses; classIndex++) {
          if (labelsArray[i + classIndex] === 1) {
            labelCounts[classIndex]++;
            break; // Cada bloque solo debe tener una clase activa
          }
        }
      }

      // Mostrar el resultado
      console.log("Distribución de clases:", labelCounts);
    }

    // Load and preprocess the MNIST dataset
    async function loadMnistData() {
      const MNIST_IMAGES_SPRITE_PATH = 'https://storage.googleapis.com/learnjs-data/model-builder/mnist_images.png';
      const MNIST_LABELS_PATH = 'https://storage.googleapis.com/learnjs-data/model-builder/mnist_labels_uint8';

      const img = new Image();
      img.crossOrigin = '';
      img.src = MNIST_IMAGES_SPRITE_PATH;
      await new Promise((resolve) => {
        img.onload = () => {
          resolve();
        };
      });

      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      const IMAGE_SIZE = 28;
      const NUM_CLASSES = 10;
      const NUM_TRAIN_IMAGES = 55000; // Training set size
      const NUM_TEST_IMAGES = 10000; // Testing set size

      canvas.width = img.width;
      canvas.height = img.height;
      ctx.drawImage(img, 0, 0);
      const datasetBytesBuffer = new Float32Array((NUM_TRAIN_IMAGES + NUM_TEST_IMAGES) * IMAGE_SIZE * IMAGE_SIZE);

      for (let i = 0; i < NUM_TRAIN_IMAGES + NUM_TEST_IMAGES; i++) {
        const x = (i % 100) * IMAGE_SIZE;
        const y = Math.floor(i / 100) * IMAGE_SIZE;
        const imageData = ctx.getImageData(x, y, IMAGE_SIZE, IMAGE_SIZE);

        for (let j = 0; j < IMAGE_SIZE * IMAGE_SIZE; j++) {
          datasetBytesBuffer[i * IMAGE_SIZE * IMAGE_SIZE + j] = imageData.data[j * 4] / 255;
        }
      }

      const labelsResponse = await fetch(MNIST_LABELS_PATH);
      const labels = new Uint8Array(await labelsResponse.arrayBuffer());
      countClassesFromOneHot(labels,NUM_CLASSES);
      countClassesFromOneHot(labels.slice(0,NUM_TRAIN_IMAGES),NUM_CLASSES);
      countClassesFromOneHot(labels.slice(NUM_TRAIN_IMAGES-1,labels.length-1),NUM_CLASSES);

      // Ensuring proper slicing for training and testing sets
      const trainImages = datasetBytesBuffer.slice(0, NUM_TRAIN_IMAGES * IMAGE_SIZE * IMAGE_SIZE);
      const testImages = datasetBytesBuffer.slice(NUM_TRAIN_IMAGES * IMAGE_SIZE * IMAGE_SIZE);
      const trainLabels = labels.slice(0, NUM_TRAIN_IMAGES); // Corrected to NUM_TRAIN_IMAGES
      const testLabels = labels.slice(NUM_TRAIN_IMAGES, NUM_TRAIN_IMAGES + NUM_TEST_IMAGES); // Corrected to NUM_TEST_IMAGES

      return {
        trainX: tf.tensor4d(trainImages, [NUM_TRAIN_IMAGES, 28, 28, 1]),
        trainY: tf.oneHot(tf.tensor1d(trainLabels, 'int32'), NUM_CLASSES),
        testX: tf.tensor4d(testImages, [NUM_TEST_IMAGES, 28, 28, 1]),
        testY: tf.oneHot(tf.tensor1d(testLabels, 'int32'), NUM_CLASSES)
      };
    }

    // Define the LeNet model
    function createLeNetModel() {
      const model = tf.sequential();

      // First convolution layer
      model.add(tf.layers.conv2d({
        inputShape: [28, 28, 1],
        filters: 6,
        kernelSize: 5,
        activation: 'tanh',
        padding: 'same'
      }));
      model.add(tf.layers.averagePooling2d({ poolSize: 2, strides: 2 }));

      // Second convolution layer
      model.add(tf.layers.conv2d({
        filters: 16,
        kernelSize: 5,
        activation: 'tanh'
      }));
      model.add(tf.layers.averagePooling2d({ poolSize: 2, strides: 2 }));

      // Flatten layer
      model.add(tf.layers.flatten());

      // Fully connected layers
      model.add(tf.layers.dense({ units: 120, activation: 'tanh' }));
      model.add(tf.layers.dense({ units: 84, activation: 'tanh' }));
      model.add(tf.layers.dense({ units: 10, activation: 'softmax' }));

      return model;
    }

    async function trainModel() {
      document.getElementById('status').innerText = 'Loading data...';
      const data = await loadMnistData();

      const model = createLeNetModel();
      model.compile({
        optimizer: 'sgd',
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy']
      });

      document.getElementById('status').innerText = 'Training model...';

      const { onEpochEnd } = tfvis.show.fitCallbacks(
        { name: 'Training Performance' },
        ['loss', 'val_loss', 'acc', 'val_acc']
      );

      // Train the model
      await model.fit(data.trainX, data.trainY, {
        epochs: 5,
        validationData: [data.testX, data.testY],
        callbacks: {
          onEpochEnd
          //onEpochEnd: (epoch, logs) => {
          //  document.getElementById('status').innerText = `Epoch ${epoch + 1}: loss = ${logs.loss.toFixed(4)}, accuracy = ${logs.acc.toFixed(8)}`;
          //}
        }
      });

      document.getElementById('status').innerText = 'Training complete. Evaluating...';

      // Evaluate the model
      const evalResult = await model.evaluate(data.testX, data.testY);
      document.getElementById('accuracy').innerText = `Test accuracy: ${(evalResult[1].dataSync()[0] * 100).toFixed(2)}%`;
    }
  </script>
</body>

</html>